{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZniIsHwZIayWki/qFp/H7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanaBell/DS2002-ETL-Project/blob/main/DS2002_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import sqlite3\n",
        "\n",
        "#Aryana Bellamkonda, Mariana Mendez, Caroline Nguyen\n",
        "# 1. Data Ingestion\n",
        "\n",
        "# Stock Data from Alpaca API\n",
        "API_KEY = \"\"       # Your Alpaca API key\n",
        "API_SECRET = \"\"  # Your Alpaca API secret key\n",
        "symbol = \"DAL\"                          # Delta Airlines ticker\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2020-12-31\"\n",
        "\n",
        "stock_url = f\"https://data.alpaca.markets/v2/stocks/{symbol}/bars\"\n",
        "headers = {\"APCA-API-KEY-ID\": API_KEY, \"APCA-API-SECRET-KEY\": API_SECRET}\n",
        "params = {\"start\": start_date, \"end\": end_date, \"timeframe\": \"1Day\"}\n",
        "response = requests.get(stock_url, headers=headers, params=params)\n",
        "response.raise_for_status()  # If the API call request fails for any reason, the code will stop\n",
        "\n",
        "stock_df = pd.DataFrame(response.json().get(\"bars\", []))\n",
        "if not stock_df.empty:\n",
        "    # Convert the timestamp column 't' to a proper date and store it in a new column \"date\"\n",
        "    stock_df[\"date\"] = pd.to_datetime(stock_df[\"t\"]).dt.date\n",
        "    # Remove the original timestamp column as it is no longer needed\n",
        "    stock_df.drop(columns=[\"t\"], inplace=True)\n",
        "  # Print a summary (number of records and columns) of the stock data\n",
        "print(\"Stock Data (Records, Columns):\", stock_df.shape)\n",
        "\n",
        "# COVID Data from local CSV file\n",
        "try:\n",
        "    covid_df = pd.read_csv(\"cumulative-deaths-and-cases-covid-19.csv\") # Read the local CSV file containing COVID data\n",
        "    covid_df.columns = covid_df.columns.str.strip()  # Clean column names\n",
        "    # Filter for US data using the \"Entity\" column and force a copy to avoid SettingWithCopyWarning\n",
        "    covid_df = covid_df[covid_df[\"Entity\"] == \"United States\"].copy()\n",
        "    # Rename the longer column names to make it easier\n",
        "    covid_df.rename(columns={\"Total confirmed cases of COVID-19\": \"total_cases\",\n",
        "                             \"Total confirmed deaths due to COVID-19\": \"total_deaths\"}, inplace=True)\n",
        "    # Convert the \"Day\" column to a proper date and add as \"date\"\n",
        "    covid_df[\"date\"] = pd.to_datetime(covid_df[\"Day\"]).dt.date\n",
        "    print(\"COVID Data (Records, Columns):\", covid_df.shape)\n",
        "except Exception as e:\n",
        "    print(\"Error reading local COVID data:\", e) #Print error message for issues reading the csv file\n",
        "    covid_df = pd.DataFrame()\n",
        "\n",
        "# 2. Data Transformation and Merging\n",
        "\n",
        "# Merge on the common \"date\" column and drop the redundant \"Day\" column\n",
        "merged_df = pd.merge(stock_df, covid_df, on=\"date\", how=\"inner\")\n",
        "merged_df = merged_df.drop(columns=[\"Day\"])\n",
        "# Print the Records and Columns and list the column names of the merged dataset\n",
        "print(\"Merged Data (Records, Columns):\", merged_df.shape)\n",
        "print(\"Columns of Merged Dataset:\", merged_df.columns.tolist())\n",
        "\n",
        "# 3. Data Analysis and Summarization\n",
        "# Calculate the correlation between the stock's closing price (\"c\") and COVID total cases (\"total_cases\")\n",
        "\n",
        "if \"c\" in merged_df.columns and \"total_cases\" in merged_df.columns:\n",
        "    corr = merged_df[\"c\"].corr(merged_df[\"total_cases\"])\n",
        "    print(\"Correlation between closing price and total confirmed cases:\", corr)\n",
        "else:\n",
        "    print(\"Required columns for correlation analysis are missing.\") #Error message\n",
        "\n",
        "print(\"\\nSummary Statistics of Merged Data:\")\n",
        "print(merged_df.describe()) #Prints statistics for the merged data set\n",
        "\n",
        "# 4. Data Storage: Output Format Selection\n",
        "# Asks the user for the desired output format: csv, json, or sql (default is sql)\n",
        "format = input(\"\\nEnter desired output format (csv, json, sql) [default: sql]: \").strip().lower()\n",
        "if format not in [\"csv\", \"json\", \"sql\"]:\n",
        "    format = \"sql\"\n",
        "if format == \"csv\":\n",
        "    merged_df.to_csv(\"merged_data.csv\", index=False)\n",
        "    print(\"Data saved as merged_data.csv\")\n",
        "elif format == \"json\":\n",
        "    merged_df.to_json(\"merged_data.json\", orient=\"records\", date_format=\"iso\")\n",
        "    print(\"Data saved as merged_data.json\")\n",
        "else:\n",
        "    conn = sqlite3.connect(\"merged_data.db\")\n",
        "    merged_df.to_sql(\"merged_data\", conn, if_exists=\"replace\", index=False)\n",
        "    conn.close()\n",
        "    print(\"Data saved in merged_data.db as a SQLite table\")\n",
        "    print(merged_df) #Prints the sql database\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaXT7yDEj8yR",
        "outputId": "ccc7c23a-a6b9-46d8-e1a5-b4363f1e1eeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Data (Records, Columns): (253, 8)\n",
            "COVID Data (Records, Columns): (1885, 6)\n",
            "Merged Data (Records, Columns): (251, 12)\n",
            "Columns of Merged Dataset: ['c', 'h', 'l', 'n', 'o', 'v', 'vw', 'date', 'Entity', 'Code', 'total_deaths', 'total_cases']\n",
            "Correlation between closing price and total confirmed cases: -0.02934458777668341\n",
            "\n",
            "Summary Statistics of Merged Data:\n",
            "                c           h           l              n           o  \\\n",
            "count  251.000000  251.000000  251.000000     251.000000  251.000000   \n",
            "mean    34.788725   35.672010   33.952502  169991.394422   34.929103   \n",
            "std     11.401663   11.348368   11.419814  118045.096721   11.389011   \n",
            "min     19.190000   19.540000   17.510000   27689.000000   18.800000   \n",
            "25%     26.900000   27.610000   26.070000   90997.000000   26.700000   \n",
            "50%     31.140000   31.960000   30.480000  132470.000000   31.250000   \n",
            "75%     40.405000   41.040000   39.895000  214935.500000   40.500000   \n",
            "max     62.030000   62.480000   61.865000  742962.000000   62.130000   \n",
            "\n",
            "                  v          vw   total_deaths   total_cases  \n",
            "count  2.510000e+02  251.000000     251.000000  2.510000e+02  \n",
            "mean   3.089339e+07   34.804691  130377.840637  4.698975e+06  \n",
            "std    2.391230e+07   11.374343  102844.738802  5.050365e+06  \n",
            "min    4.131501e+06   18.718548       0.000000  0.000000e+00  \n",
            "25%    1.451631e+07   26.777189    8174.500000  2.876035e+05  \n",
            "50%    2.223769e+07   31.213511  132208.000000  2.916521e+06  \n",
            "75%    4.363732e+07   40.536680  211297.000000  7.278925e+06  \n",
            "max    1.352232e+08   62.080298  352004.000000  1.957758e+07  \n",
            "\n",
            "Enter desired output format (csv, json, sql) [default: sql]: sql\n",
            "Data saved in merged_data.db as a SQLite table\n",
            "         c        h       l      n      o         v         vw        date  \\\n",
            "0    57.66  57.7600  56.660  38426  56.99   6274401  57.532589  2020-01-06   \n",
            "1    57.61  58.0700  57.470  36887  57.91   6497133  57.720580  2020-01-07   \n",
            "2    58.85  59.4000  57.730  50326  57.75   9666831  58.844094  2020-01-08   \n",
            "3    58.96  59.4700  58.580  38926  59.26   5922812  58.969447  2020-01-09   \n",
            "4    59.24  59.4900  58.620  50097  59.25   9602132  59.210451  2020-01-10   \n",
            "..     ...      ...     ...    ...    ...       ...        ...         ...   \n",
            "246  39.73  40.4400  39.605  38062  40.42   5689467  39.818570  2020-12-24   \n",
            "247  40.15  40.7758  40.010  72937  40.27  11337400  40.400665  2020-12-28   \n",
            "248  40.03  40.8400  39.900  60959  40.84   9094195  40.210880  2020-12-29   \n",
            "249  40.56  40.9050  39.890  65529  40.00   9092671  40.527405  2020-12-30   \n",
            "250  40.21  40.7400  39.760  61465  40.27   9325574  40.317526  2020-12-31   \n",
            "\n",
            "            Entity Code  total_deaths  total_cases  \n",
            "0    United States  USA             0            0  \n",
            "1    United States  USA             0            0  \n",
            "2    United States  USA             0            0  \n",
            "3    United States  USA             0            0  \n",
            "4    United States  USA             0            0  \n",
            "..             ...  ...           ...          ...  \n",
            "246  United States  USA        334424     18300354  \n",
            "247  United States  USA        344570     19037565  \n",
            "248  United States  USA        346473     19191907  \n",
            "249  United States  USA        348653     19368681  \n",
            "250  United States  USA        352004     19577585  \n",
            "\n",
            "[251 rows x 12 columns]\n"
          ]
        }
      ]
    }
  ]
}